{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'sentence', 'label'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['idx', 'sentence', 'label'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['idx', 'sentence', 'label'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pysentimiento import create_analyzer\n",
    "from textblob import TextBlob\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "benchmark_datasets = {\n",
    "    \"sentiment\": [\"stanfordnlp/sst2\", \"takala/financial_phrasebank\"]\n",
    "}\n",
    "\n",
    "analyzer = create_analyzer(\"sentiment\", lang=\"en\")\n",
    "\n",
    "\n",
    "ds = load_dataset(benchmark_datasets[\"sentiment\"][0])\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': Value(dtype='int32', id=None),\n",
       " 'sentence': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['negative', 'positive'], id=None)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 02:44:11 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624d05e09d884c9992bf9cdbde1c6418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 02:44:11 INFO: Downloaded file to /users/jmperez/stanza_resources/resources.json\n",
      "2024-06-15 02:44:11 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-06-15 02:44:12 INFO: Loading these models for language: en (English):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | combined       |\n",
      "| mwt       | combined       |\n",
      "| sentiment | sstplus_charlm |\n",
      "==============================\n",
      "\n",
      "2024-06-15 02:44:12 INFO: Using device: cuda\n",
      "2024-06-15 02:44:12 INFO: Loading: tokenize\n",
      "2024-06-15 02:44:12 INFO: Loading: mwt\n",
      "2024-06-15 02:44:12 INFO: Loading: sentiment\n",
      "2024-06-15 02:44:13 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36593a155a194980bfe679342a463b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226e3f45287941958d934e22b1218570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/872 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea597db87b3b4084841c7f3e9be920a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/872 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import stanza\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', tokenize_no_ssplit=True)\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "\n",
    "pysentimiento_outs = analyzer.predict(ds[\"validation\"][\"sentence\"])\n",
    "textblob_outs = [TextBlob(x).sentiment.polarity for x in tqdm(ds[\"validation\"][\"sentence\"])]\n",
    "vader_outs = [vader.polarity_scores(x) for x in tqdm(ds[\"validation\"][\"sentence\"])]\n",
    "stanza_outs = nlp(ds[\"validation\"][\"sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "preds = {}\n",
    "\n",
    "# Get NEG or POS --ignore NEU\n",
    "preds[\"pysentimiento\"] = [\"negative\" if x.probas[\"NEG\"] > x.probas[\"POS\"] else \"positive\" for x in pysentimiento_outs]\n",
    "\n",
    "preds[\"textblob\"] = [\"negative\" if x < 0 else \"positive\" for x in textblob_outs]\n",
    "\n",
    "preds[\"vader\"] = [\"negative\" if x[\"neg\"] > x[\"pos\"] else \"positive\" for x in vader_outs]\n",
    "\n",
    "def get_stanza_sentiment(x):\n",
    "    if x.sentiment == 0:\n",
    "        return \"negative\"\n",
    "    elif x.sentiment == 2:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        # Flip a coin\n",
    "        if random.random() > 0.5:\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\"\n",
    "\n",
    "preds[\"stanza\"] = [get_stanza_sentiment(x) for x in stanza_outs.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pysentimiento\n",
      "textblob\n",
      "vader\n",
      "stanza\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "id2label = [\"negative\", \"positive\"]\n",
    "label2id = {label: i for i, label in enumerate(id2label)}\n",
    "\n",
    "\n",
    "results = {}\n",
    "for name, pred in preds.items():\n",
    "    print(name)\n",
    "    true_labels = ds[\"validation\"][\"label\"]\n",
    "    pred_labels = [label2id[x] for x in pred]\n",
    "\n",
    "    ret = classification_report(true_labels, pred_labels, target_names=id2label, output_dict=True)\n",
    "\n",
    "    res = {\n",
    "        \"Negative F1\": ret[\"negative\"][\"f1-score\"],\n",
    "        \"Positive F1\": ret[\"positive\"][\"f1-score\"],\n",
    "        \"Macro F1\": ret[\"macro avg\"][\"f1-score\"],\n",
    "        \"Macro Precision\": ret[\"macro avg\"][\"precision\"],\n",
    "        \"Macro Recall\": ret[\"macro avg\"][\"recall\"],\n",
    "    }\n",
    "    results[name] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative F1</th>\n",
       "      <th>Positive F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pysentimiento</th>\n",
       "      <td>87.573964</td>\n",
       "      <td>88.320356</td>\n",
       "      <td>87.947160</td>\n",
       "      <td>87.990882</td>\n",
       "      <td>87.931506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob</th>\n",
       "      <td>50.909091</td>\n",
       "      <td>70.110701</td>\n",
       "      <td>60.509896</td>\n",
       "      <td>65.894397</td>\n",
       "      <td>62.418961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vader</th>\n",
       "      <td>51.885370</td>\n",
       "      <td>70.490287</td>\n",
       "      <td>61.187828</td>\n",
       "      <td>66.501553</td>\n",
       "      <td>62.998863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stanza</th>\n",
       "      <td>84.976526</td>\n",
       "      <td>85.650224</td>\n",
       "      <td>85.313375</td>\n",
       "      <td>85.322608</td>\n",
       "      <td>85.307738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Negative F1  Positive F1   Macro F1  Macro Precision  \\\n",
       "pysentimiento    87.573964    88.320356  87.947160        87.990882   \n",
       "textblob         50.909091    70.110701  60.509896        65.894397   \n",
       "vader            51.885370    70.490287  61.187828        66.501553   \n",
       "stanza           84.976526    85.650224  85.313375        85.322608   \n",
       "\n",
       "               Macro Recall  \n",
       "pysentimiento     87.931506  \n",
       "textblob          62.418961  \n",
       "vader             62.998863  \n",
       "stanza            85.307738  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results).T\n",
    "\n",
    "\n",
    "df * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Financial Phrasebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 4217\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ds = load_dataset(\"takala/financial_phrasebank\", \"sentences_66agree\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['negative', 'neutral', 'positive'],\n",
       " {'negative': 0, 'neutral': 1, 'positive': 2})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = ds[\"train\"].features[\"label\"].names\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(id2label)}\n",
    "\n",
    "id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937c0f4d1b58436997a108d6b0eda233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4217 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4d353e90494e6e882931427673a63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11676066e7c7441d81283d90b24a4b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pysentimiento_outs = analyzer.predict(ds[\"train\"][\"sentence\"])\n",
    "textblob_outs = [TextBlob(x).sentiment.polarity for x in tqdm(ds[\"train\"][\"sentence\"])]\n",
    "vader_outs = [vader.polarity_scores(x) for x in tqdm(ds[\"train\"][\"sentence\"])]\n",
    "stanza_outs = nlp(ds[\"train\"][\"sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = ds[\"train\"][0]\n",
    "\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(ex[\"sentence\"]).sentences[0].sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "preds = {}\n",
    "\n",
    "# Get NEG or POS --ignore NEU\n",
    "pysent_mask = {\"NEG\": \"negative\", \"POS\": \"positive\", \"NEU\": \"neutral\"}\n",
    "\n",
    "preds[\"pysentimiento\"] = [pysent_mask[x.output] for x in pysentimiento_outs]\n",
    "\n",
    "def get_textblob_sentiment(x, neutral_threshold=0.1):\n",
    "    if x < -neutral_threshold:\n",
    "        return \"negative\"\n",
    "    elif x > neutral_threshold:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "preds[\"textblob\"] = [get_textblob_sentiment(x) for x in textblob_outs]\n",
    "\n",
    "def get_vader_sentiment(x):\n",
    "    sents = [\"neg\", \"neu\", \"pos\"]\n",
    "\n",
    "    # get argmax\n",
    "    max_sent = max(range(len(sents)), key=lambda i: x[sents[i]])\n",
    "\n",
    "    return id2label[max_sent]\n",
    "\n",
    "preds[\"vader\"] = [get_vader_sentiment(x) for x in vader_outs]\n",
    "\n",
    "\n",
    "preds[\"stanza\"] = [id2label[x.sentiment] for x in stanza_outs.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pysentimiento\n",
      "textblob\n",
      "vader\n",
      "stanza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "results = {}\n",
    "for name, pred in preds.items():\n",
    "    print(name)\n",
    "    true_labels = ds[\"train\"][\"label\"]\n",
    "    pred_labels = [label2id[x] for x in pred]\n",
    "\n",
    "    ret = classification_report(true_labels, pred_labels, target_names=id2label, output_dict=True)\n",
    "\n",
    "    res = {\n",
    "        \"Negative F1\": ret[\"negative\"][\"f1-score\"],\n",
    "        \"Positive F1\": ret[\"positive\"][\"f1-score\"],\n",
    "        \"Macro F1\": ret[\"macro avg\"][\"f1-score\"],\n",
    "        \"Macro Precision\": ret[\"macro avg\"][\"precision\"],\n",
    "        \"Macro Recall\": ret[\"macro avg\"][\"recall\"],\n",
    "    }\n",
    "    results[name] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative F1</th>\n",
       "      <th>Positive F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pysentimiento</th>\n",
       "      <td>0.637441</td>\n",
       "      <td>0.609615</td>\n",
       "      <td>0.682352</td>\n",
       "      <td>0.750389</td>\n",
       "      <td>0.645194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob</th>\n",
       "      <td>0.289238</td>\n",
       "      <td>0.377609</td>\n",
       "      <td>0.448512</td>\n",
       "      <td>0.466919</td>\n",
       "      <td>0.439714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vader</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>0.251322</td>\n",
       "      <td>0.333713</td>\n",
       "      <td>0.333510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stanza</th>\n",
       "      <td>0.313076</td>\n",
       "      <td>0.324654</td>\n",
       "      <td>0.441454</td>\n",
       "      <td>0.463273</td>\n",
       "      <td>0.444095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Negative F1  Positive F1  Macro F1  Macro Precision  \\\n",
       "pysentimiento     0.637441     0.609615  0.682352         0.750389   \n",
       "textblob          0.289238     0.377609  0.448512         0.466919   \n",
       "vader             0.000000     0.003410  0.251322         0.333713   \n",
       "stanza            0.313076     0.324654  0.441454         0.463273   \n",
       "\n",
       "               Macro Recall  \n",
       "pysentimiento      0.645194  \n",
       "textblob           0.439714  \n",
       "vader              0.333510  \n",
       "stanza             0.444095  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results).T\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
